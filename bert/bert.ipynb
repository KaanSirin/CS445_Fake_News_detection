{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='4DA1A9'>The outline of these notebooks were influenced by Phil Schmid's [blog post](https://www.philschmid.de/fine-tune-modern-bert-in-2025) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> Loading The Data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names=[\n",
    "        'id',                # Column 1: the ID of the statement ([ID].json).\n",
    "        'label',             # Column 2: the label.\n",
    "        'statement',         # Column 3: the statement.\n",
    "        'subjects',          # Column 4: the subject(s).\n",
    "        'speaker',           # Column 5: the speaker.\n",
    "        'speaker_job_title', # Column 6: the speaker's job title.\n",
    "        'state_info',        # Column 7: the state info.\n",
    "        'party_affiliation', # Column 8: the party affiliation.\n",
    "        \n",
    "        # Column 9-13: the total credit history count, including the current statement.\n",
    "        'count_1', # barely true counts.\n",
    "        'count_2', # false counts.\n",
    "        'count_3', # half true counts.\n",
    "        'count_4', # mostly true counts.\n",
    "        'count_5', # pants on fire counts.\n",
    "\n",
    "        'context' # Column 14: the context (venue / location of the speech or statement).\n",
    "]\n",
    "\n",
    "train_data = pd.read_csv('./liar_dataset/train.tsv', sep='\\t', header=None, names=column_names)\n",
    "test_data  = pd.read_csv('./liar_dataset/test.tsv',  sep='\\t', header=None, names=column_names)\n",
    "valid_data = pd.read_csv('./liar_dataset/valid.tsv', sep='\\t', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> Preprocessing the Data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def preprocess_data(data:pd.DataFrame, six_way:bool=True, metadata:bool=True):\n",
    "\n",
    "    #Â these data are not usable\n",
    "    data.drop(columns=[f'count_{i+1}' for i in range(5)], inplace=True)\n",
    "\n",
    "    # encoding output labels \n",
    "    if six_way:\n",
    "        numerical={'pants-fire': 0, 'false': 1, 'barely-true': 2, 'half-true': 3, 'mostly-true': 4, 'true': 5}\n",
    "        data['label'] = data['label'].map(numerical)\n",
    "    else:\n",
    "        true_labels= ['true', 'mostly-true', 'half-true']\n",
    "        data['label'] = data['label'].apply(lambda x: 1 if x in true_labels else 0)\n",
    "\n",
    "    # fill missing columns\n",
    "    data.fillna('',inplace=True)\n",
    "\n",
    "    # adding metadata\n",
    "    if metadata:\n",
    "        data['statement'] = data['statement'] + ' ' + data['speaker'] + ' ' + data['speaker_job_title'] + ' ' + data['state_info'] + ' ' + data['party_affiliation'] + ' ' + data['context']\n",
    "\n",
    "    # dropping every column other than label and statement\n",
    "    data.drop(columns=data.columns.difference(['label', 'statement']), inplace=True)\n",
    "\n",
    "    # data_dict= data.to_dict(orient='records')\n",
    "    # return data_dict\n",
    "    return Dataset.from_pandas(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= preprocess_data(train_data)\n",
    "test_data= preprocess_data(test_data)\n",
    "valid_data= preprocess_data(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> I like it better when it is a single dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import dataset_dict\n",
    "\n",
    "dataset_dict= dataset_dict.DatasetDict()\n",
    "\n",
    "dataset_dict['train']= train_data\n",
    "dataset_dict['test']= test_data\n",
    "dataset_dict['valid']= valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'statement'],\n",
       "        num_rows: 10240\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'statement'],\n",
       "        num_rows: 1267\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['label', 'statement'],\n",
       "        num_rows: 1284\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cta/users/kguray/.venv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DebertaV2Tokenizer\n",
    "import torch\n",
    "\n",
    "model_id = \"microsoft/deberta-v3-base\"\n",
    "# model_id = \"google-bert/bert-base-uncased\"\n",
    "# model_id='distilbert/distilbert-base-uncased'\n",
    "# model_id = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.model_max_length=512\n",
    "\n",
    "\n",
    "# Tokenize function\n",
    "def tokenizer_helper(sample):\n",
    "    return tokenizer(sample['statement'], padding='max_length', truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff03e11e0c46478683f33870a85037de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86be19ca4cd44af190822b797008a343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1267 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e796dc4e623436dae44623aeba6cc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1284 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the data\n",
    "\n",
    "tokenized_dataset= dataset_dict.map(tokenizer_helper, batched=True, remove_columns=['statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 10240\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1267\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1284\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# model_id = \"microsoft/deberta-v3-base\"\n",
    "# model_id = \"google-bert/bert-base-uncased\"\n",
    "# model_id='distilbert/distilbert-base-uncased'\n",
    "\n",
    "\n",
    "labels_2_id={'pants-fire': 0, 'false': 1, 'barely-true': 2, 'half-true': 3, 'mostly-true': 4, 'true': 5}\n",
    "id_2_labels={v:k for k,v in labels_2_id.items()}\n",
    "# id_2_labels={0:'false',1:'true'}\n",
    "# labels_2_id={v:k for k,v in id_2_labels.items()}\n",
    "\n",
    "model=AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id, torch_dtype=torch.bfloat16, label2id=labels_2_id, id2label=id_2_labels, num_labels=len(id_2_labels)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the model to run on device\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model=model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, accuracy_score\n",
    " \n",
    "# Metric helper method\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    " \n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"other_bert\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=3,\n",
    "    bf16=True, # bfloat16 training \n",
    "    optim=\"adamw_torch_fused\", # improved optimizer \n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    # logging & evaluation strategies\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    " \n",
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['valid'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1920' max='1920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1920/1920 10:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.686300</td>\n",
       "      <td>0.712296</td>\n",
       "      <td>0.520249</td>\n",
       "      <td>0.356072</td>\n",
       "      <td>0.270659</td>\n",
       "      <td>0.520249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.689100</td>\n",
       "      <td>0.692874</td>\n",
       "      <td>0.520249</td>\n",
       "      <td>0.356072</td>\n",
       "      <td>0.270659</td>\n",
       "      <td>0.520249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.683800</td>\n",
       "      <td>0.694399</td>\n",
       "      <td>0.520249</td>\n",
       "      <td>0.356072</td>\n",
       "      <td>0.270659</td>\n",
       "      <td>0.520249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cta/users/kguray/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/cta/users/kguray/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/cta/users/kguray/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1920, training_loss=0.686629002292951, metrics={'train_runtime': 618.2168, 'train_samples_per_second': 49.691, 'train_steps_per_second': 3.106, 'total_flos': 8082916575805440.0, 'train_loss': 0.686629002292951, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6761326193809509,\n",
       " 'eval_accuracy': 0.659037095501184,\n",
       " 'eval_f1': 0.6547883036136438,\n",
       " 'eval_precision': 0.6559005596062724,\n",
       " 'eval_recall': 0.659037095501184,\n",
       " 'eval_runtime': 4.7314,\n",
       " 'eval_samples_per_second': 267.788,\n",
       " 'eval_steps_per_second': 16.908,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_dataset['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
